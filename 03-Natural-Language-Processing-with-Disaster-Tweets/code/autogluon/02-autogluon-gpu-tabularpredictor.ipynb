{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T00:07:39.550352Z","iopub.execute_input":"2022-01-21T00:07:39.550889Z","iopub.status.idle":"2022-01-21T00:07:39.586573Z","shell.execute_reply.started":"2022-01-21T00:07:39.550794Z","shell.execute_reply":"2022-01-21T00:07:39.585740Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install autogluon","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:10:49.938405Z","iopub.execute_input":"2022-01-21T00:10:49.938685Z","iopub.status.idle":"2022-01-21T00:11:41.738864Z","shell.execute_reply.started":"2022-01-21T00:10:49.938653Z","shell.execute_reply":"2022-01-21T00:11:41.738032Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/nlpgettingstarted/train.csv')\ntest = pd.read_csv('../input/nlpgettingstarted/test.csv')\nsubmission = pd.read_csv('../input/nlpgettingstarted/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:28:54.114617Z","iopub.execute_input":"2022-01-21T00:28:54.115725Z","iopub.status.idle":"2022-01-21T00:28:54.180589Z","shell.execute_reply.started":"2022-01-21T00:28:54.115681Z","shell.execute_reply":"2022-01-21T00:28:54.179913Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:28:55.994885Z","iopub.execute_input":"2022-01-21T00:28:55.995682Z","iopub.status.idle":"2022-01-21T00:28:56.007342Z","shell.execute_reply.started":"2022-01-21T00:28:55.995644Z","shell.execute_reply":"2022-01-21T00:28:56.006668Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/swarnabha/pytorch-text-classification-torchtext-lstm\ndef clean_text (text):\n    text = text.str.lower() # lowercase\n    text = text.str.replace(r\"\\#\",\"\") # replaces hashtags\n    text = text.str.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n    text = text.str.replace(r\"@\",\"\")\n    text = text.str.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n    text = text.str.replace(\"\\s{2,}\", \" \")\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:28:57.650767Z","iopub.execute_input":"2022-01-21T00:28:57.651051Z","iopub.status.idle":"2022-01-21T00:28:57.662215Z","shell.execute_reply.started":"2022-01-21T00:28:57.651002Z","shell.execute_reply":"2022-01-21T00:28:57.658169Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove\n\nimport re\ndef remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\nimport string\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:28:59.347444Z","iopub.execute_input":"2022-01-21T00:28:59.348290Z","iopub.status.idle":"2022-01-21T00:28:59.356396Z","shell.execute_reply.started":"2022-01-21T00:28:59.348239Z","shell.execute_reply":"2022-01-21T00:28:59.355682Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/faressayah/sentiment-model-with-tensorflow-transformers\ndef decontraction(text):\n    text = re.sub(r\"won\\'t\", \" will not\", text)\n    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n    text = re.sub(r\"can\\'t\", \" can not\", text)\n    text = re.sub(r\"don\\'t\", \" do not\", text)\n    \n    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n    text = re.sub(r\"ma\\'am\", \" madam\", text)\n    text = re.sub(r\"let\\'s\", \" let us\", text)\n    text = re.sub(r\"ain\\'t\", \" am not\", text)\n    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n    text = re.sub(r\"y\\'all\", \" you all\", text)\n\n    text = re.sub(r\"n\\'t\", \" not\", text)\n    text = re.sub(r\"n\\'t've\", \" not have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'d've\", \" would have\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ll've\", \" will have\", text)\n    text = re.sub(r\"\\'t\", \" not\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'m\", \" am\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    return text \n\ndef seperate_alphanumeric(text):\n    words = text\n    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n    return \" \".join(words)\n\ndef cont_rep_char(text):\n    tchr = text.group(0) \n    \n    if len(tchr) > 1:\n        return tchr[0:2] \n\ndef unique_char(rep, text):\n    substitute = re.sub(r'(\\w)\\1+', rep, text)\n    return substitute","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:29:01.671656Z","iopub.execute_input":"2022-01-21T00:29:01.672519Z","iopub.status.idle":"2022-01-21T00:29:01.689104Z","shell.execute_reply.started":"2022-01-21T00:29:01.672459Z","shell.execute_reply":"2022-01-21T00:29:01.688358Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train['text'] = clean_text(train['text'])\ntest['text'] = clean_text(test['text'])\n\ntrain['text']=train['text'].apply(lambda x : remove_URL(x))\ntest['text']=test['text'].apply(lambda x : remove_URL(x))\n\ntrain['text']=train['text'].apply(lambda x : remove_html(x))\ntest['text']=test['text'].apply(lambda x : remove_html(x))\n\ntrain['text']=train['text'].apply(lambda x: remove_emoji(x))\ntest['text']=test['text'].apply(lambda x: remove_emoji(x))\n\ntrain['text']=train['text'].apply(lambda x : remove_punct(x))\ntest['text']=test['text'].apply(lambda x : remove_punct(x))\n\ntrain['text'] = train['text'].apply(lambda x : decontraction(x))\ntest['text'] = test['text'].apply(lambda x : decontraction(x))\n\ntrain['text'] = train['text'].apply(lambda x : seperate_alphanumeric(x))\ntest['text'] = test['text'].apply(lambda x : seperate_alphanumeric(x))\n\ntrain['text'] = train['text'].apply(lambda x : unique_char(cont_rep_char, x))\ntest['text'] = test['text'].apply(lambda x : unique_char(cont_rep_char, x))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:29:04.130980Z","iopub.execute_input":"2022-01-21T00:29:04.131721Z","iopub.status.idle":"2022-01-21T00:29:05.066729Z","shell.execute_reply.started":"2022-01-21T00:29:04.131682Z","shell.execute_reply":"2022-01-21T00:29:05.065937Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/nxhong93/tweet-predict1\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"couldnt\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"doesnt\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"havent\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"shouldnt\" : \"should not\",\n\"that's\" : \"that is\",\n\"thats\" : \"that is\",\n\"there's\" : \"there is\",\n\"theres\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"theyre\":  \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\"}\n\npuncts = puncts + list(string.punctuation)\n\ndef clean_text(x):\n    x = str(x).replace(\"\\n\",\"\")\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\n\ndef clean_numbers(x):\n    x = re.sub('\\d+', ' ', x)\n    return x\n\n\ndef replace_typical_misspell(text):\n    mispellings_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n\n    def replace(match):\n        return mispell_dict[match.group(0)]\n\n    return mispellings_re.sub(replace, text)\n\nfrom bs4 import BeautifulSoup\ndef remove_space(string):\n    string = BeautifulSoup(string).text.strip().lower()\n    string = re.sub(r'((http)\\S+)', 'http', string)\n    string = re.sub(r'\\s+', ' ', string)\n    return string\n\n\ndef clean_data(df, columns: list):\n    \n    for col in columns:\n        df[col] = df[col].apply(lambda x: remove_space(x).lower())        \n        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n        df[col] = df[col].apply(lambda x: clean_text(x))\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:29:48.318239Z","iopub.execute_input":"2022-01-21T00:29:48.318505Z","iopub.status.idle":"2022-01-21T00:29:48.558758Z","shell.execute_reply.started":"2022-01-21T00:29:48.318474Z","shell.execute_reply":"2022-01-21T00:29:48.558065Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train = train.loc[:, ['text', 'target']]\ntest = test.loc[:, ['id', 'text']]\n\ntest = clean_data(test, ['text'])\ntrain = clean_data(train, ['text'])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:21.499895Z","iopub.execute_input":"2022-01-21T00:30:21.500606Z","iopub.status.idle":"2022-01-21T00:30:24.406999Z","shell.execute_reply.started":"2022-01-21T00:30:21.500569Z","shell.execute_reply":"2022-01-21T00:30:24.406253Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:27.372802Z","iopub.execute_input":"2022-01-21T00:30:27.373094Z","iopub.status.idle":"2022-01-21T00:30:27.380950Z","shell.execute_reply.started":"2022-01-21T00:30:27.373059Z","shell.execute_reply":"2022-01-21T00:30:27.380301Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:29.601454Z","iopub.execute_input":"2022-01-21T00:30:29.601704Z","iopub.status.idle":"2022-01-21T00:30:29.611552Z","shell.execute_reply.started":"2022-01-21T00:30:29.601674Z","shell.execute_reply":"2022-01-21T00:30:29.610698Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/joswin/bert-try\nimport re\nimport string\n# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\nabbreviations = {\n    \"$\" : \" dollar \",\n    \"€\" : \" euro \",\n    \"4ao\" : \"for adults only\",\n    \"a.m\" : \"before midday\",\n    \"a3\" : \"anytime anywhere anyplace\",\n    \"aamof\" : \"as a matter of fact\",\n    \"acct\" : \"account\",\n    \"adih\" : \"another day in hell\",\n    \"afaic\" : \"as far as i am concerned\",\n    \"afaict\" : \"as far as i can tell\",\n    \"afaik\" : \"as far as i know\",\n    \"afair\" : \"as far as i remember\",\n    \"afk\" : \"away from keyboard\",\n    \"app\" : \"application\",\n    \"approx\" : \"approximately\",\n    \"apps\" : \"applications\",\n    \"asap\" : \"as soon as possible\",\n    \"asl\" : \"age, sex, location\",\n    \"atk\" : \"at the keyboard\",\n    \"ave.\" : \"avenue\",\n    \"aymm\" : \"are you my mother\",\n    \"ayor\" : \"at your own risk\", \n    \"b&b\" : \"bed and breakfast\",\n    \"b+b\" : \"bed and breakfast\",\n    \"b.c\" : \"before christ\",\n    \"b2b\" : \"business to business\",\n    \"b2c\" : \"business to customer\",\n    \"b4\" : \"before\",\n    \"b4n\" : \"bye for now\",\n    \"b@u\" : \"back at you\",\n    \"bae\" : \"before anyone else\",\n    \"bak\" : \"back at keyboard\",\n    \"bbbg\" : \"bye bye be good\",\n    \"bbc\" : \"british broadcasting corporation\",\n    \"bbias\" : \"be back in a second\",\n    \"bbl\" : \"be back later\",\n    \"bbs\" : \"be back soon\",\n    \"be4\" : \"before\",\n    \"bfn\" : \"bye for now\",\n    \"blvd\" : \"boulevard\",\n    \"bout\" : \"about\",\n    \"brb\" : \"be right back\",\n    \"bros\" : \"brothers\",\n    \"brt\" : \"be right there\",\n    \"bsaaw\" : \"big smile and a wink\",\n    \"btw\" : \"by the way\",\n    \"bwl\" : \"bursting with laughter\",\n    \"c/o\" : \"care of\",\n    \"cet\" : \"central european time\",\n    \"cf\" : \"compare\",\n    \"cia\" : \"central intelligence agency\",\n    \"csl\" : \"can not stop laughing\",\n    \"cu\" : \"see you\",\n    \"cul8r\" : \"see you later\",\n    \"cv\" : \"curriculum vitae\",\n    \"cwot\" : \"complete waste of time\",\n    \"cya\" : \"see you\",\n    \"cyt\" : \"see you tomorrow\",\n    \"dae\" : \"does anyone else\",\n    \"dbmib\" : \"do not bother me i am busy\",\n    \"diy\" : \"do it yourself\",\n    \"dm\" : \"direct message\",\n    \"dwh\" : \"during work hours\",\n    \"e123\" : \"easy as one two three\",\n    \"eet\" : \"eastern european time\",\n    \"eg\" : \"example\",\n    \"embm\" : \"early morning business meeting\",\n    \"encl\" : \"enclosed\",\n    \"encl.\" : \"enclosed\",\n    \"etc\" : \"and so on\",\n    \"faq\" : \"frequently asked questions\",\n    \"fawc\" : \"for anyone who cares\",\n    \"fb\" : \"facebook\",\n    \"fc\" : \"fingers crossed\",\n    \"fig\" : \"figure\",\n    \"fimh\" : \"forever in my heart\", \n    \"ft.\" : \"feet\",\n    \"ft\" : \"featuring\",\n    \"ftl\" : \"for the loss\",\n    \"ftw\" : \"for the win\",\n    \"fwiw\" : \"for what it is worth\",\n    \"fyi\" : \"for your information\",\n    \"g9\" : \"genius\",\n    \"gahoy\" : \"get a hold of yourself\",\n    \"gal\" : \"get a life\",\n    \"gcse\" : \"general certificate of secondary education\",\n    \"gfn\" : \"gone for now\",\n    \"gg\" : \"good game\",\n    \"gl\" : \"good luck\",\n    \"glhf\" : \"good luck have fun\",\n    \"gmt\" : \"greenwich mean time\",\n    \"gmta\" : \"great minds think alike\",\n    \"gn\" : \"good night\",\n    \"g.o.a.t\" : \"greatest of all time\",\n    \"goat\" : \"greatest of all time\",\n    \"goi\" : \"get over it\",\n    \"gps\" : \"global positioning system\",\n    \"gr8\" : \"great\",\n    \"gratz\" : \"congratulations\",\n    \"gyal\" : \"girl\",\n    \"h&c\" : \"hot and cold\",\n    \"hp\" : \"horsepower\",\n    \"hr\" : \"hour\",\n    \"hrh\" : \"his royal highness\",\n    \"ht\" : \"height\",\n    \"ibrb\" : \"i will be right back\",\n    \"ic\" : \"i see\",\n    \"icq\" : \"i seek you\",\n    \"icymi\" : \"in case you missed it\",\n    \"idc\" : \"i do not care\",\n    \"idgadf\" : \"i do not give a damn fuck\",\n    \"idgaf\" : \"i do not give a fuck\",\n    \"idk\" : \"i do not know\",\n    \"ie\" : \"that is\",\n    \"i.e\" : \"that is\",\n    \"ifyp\" : \"i feel your pain\",\n    \"IG\" : \"instagram\",\n    \"iirc\" : \"if i remember correctly\",\n    \"ilu\" : \"i love you\",\n    \"ily\" : \"i love you\",\n    \"imho\" : \"in my humble opinion\",\n    \"imo\" : \"in my opinion\",\n    \"imu\" : \"i miss you\",\n    \"iow\" : \"in other words\",\n    \"irl\" : \"in real life\",\n    \"j4f\" : \"just for fun\",\n    \"jic\" : \"just in case\",\n    \"jk\" : \"just kidding\",\n    \"jsyk\" : \"just so you know\",\n    \"l8r\" : \"later\",\n    \"lb\" : \"pound\",\n    \"lbs\" : \"pounds\",\n    \"ldr\" : \"long distance relationship\",\n    \"lmao\" : \"laugh my ass off\",\n    \"lmfao\" : \"laugh my fucking ass off\",\n    \"lol\" : \"laughing out loud\",\n    \"ltd\" : \"limited\",\n    \"ltns\" : \"long time no see\",\n    \"m8\" : \"mate\",\n    \"mf\" : \"motherfucker\",\n    \"mfs\" : \"motherfuckers\",\n    \"mfw\" : \"my face when\",\n    \"mofo\" : \"motherfucker\",\n    \"mph\" : \"miles per hour\",\n    \"mr\" : \"mister\",\n    \"mrw\" : \"my reaction when\",\n    \"ms\" : \"miss\",\n    \"mte\" : \"my thoughts exactly\",\n    \"nagi\" : \"not a good idea\",\n    \"nbc\" : \"national broadcasting company\",\n    \"nbd\" : \"not big deal\",\n    \"nfs\" : \"not for sale\",\n    \"ngl\" : \"not going to lie\",\n    \"nhs\" : \"national health service\",\n    \"nrn\" : \"no reply necessary\",\n    \"nsfl\" : \"not safe for life\",\n    \"nsfw\" : \"not safe for work\",\n    \"nth\" : \"nice to have\",\n    \"nvr\" : \"never\",\n    \"nyc\" : \"new york city\",\n    \"oc\" : \"original content\",\n    \"og\" : \"original\",\n    \"ohp\" : \"overhead projector\",\n    \"oic\" : \"oh i see\",\n    \"omdb\" : \"over my dead body\",\n    \"omg\" : \"oh my god\",\n    \"omw\" : \"on my way\",\n    \"p.a\" : \"per annum\",\n    \"p.m\" : \"after midday\",\n    \"pm\" : \"prime minister\",\n    \"poc\" : \"people of color\",\n    \"pov\" : \"point of view\",\n    \"pp\" : \"pages\",\n    \"ppl\" : \"people\",\n    \"prw\" : \"parents are watching\",\n    \"ps\" : \"postscript\",\n    \"pt\" : \"point\",\n    \"ptb\" : \"please text back\",\n    \"pto\" : \"please turn over\",\n    \"qpsa\" : \"what happens\", #\"que pasa\",\n    \"ratchet\" : \"rude\",\n    \"rbtl\" : \"read between the lines\",\n    \"rlrt\" : \"real life retweet\", \n    \"rofl\" : \"rolling on the floor laughing\",\n    \"roflol\" : \"rolling on the floor laughing out loud\",\n    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n    \"rt\" : \"retweet\",\n    \"ruok\" : \"are you ok\",\n    \"sfw\" : \"safe for work\",\n    \"sk8\" : \"skate\",\n    \"smh\" : \"shake my head\",\n    \"sq\" : \"square\",\n    \"srsly\" : \"seriously\", \n    \"ssdd\" : \"same stuff different day\",\n    \"tbh\" : \"to be honest\",\n    \"tbs\" : \"tablespooful\",\n    \"tbsp\" : \"tablespooful\",\n    \"tfw\" : \"that feeling when\",\n    \"thks\" : \"thank you\",\n    \"tho\" : \"though\",\n    \"thx\" : \"thank you\",\n    \"tia\" : \"thanks in advance\",\n    \"til\" : \"today i learned\",\n    \"tl;dr\" : \"too long i did not read\",\n    \"tldr\" : \"too long i did not read\",\n    \"tmb\" : \"tweet me back\",\n    \"tntl\" : \"trying not to laugh\",\n    \"ttyl\" : \"talk to you later\",\n    \"u\" : \"you\",\n    \"u2\" : \"you too\",\n    \"u4e\" : \"yours for ever\",\n    \"utc\" : \"coordinated universal time\",\n    \"w/\" : \"with\",\n    \"w/o\" : \"without\",\n    \"w8\" : \"wait\",\n    \"wassup\" : \"what is up\",\n    \"wb\" : \"welcome back\",\n    \"wtf\" : \"what the fuck\",\n    \"wtg\" : \"way to go\",\n    \"wtpa\" : \"where the party at\",\n    \"wuf\" : \"where are you from\",\n    \"wuzup\" : \"what is up\",\n    \"wywh\" : \"wish you were here\",\n    \"yd\" : \"yard\",\n    \"ygtr\" : \"you got that right\",\n    \"ynk\" : \"you never know\",\n    \"zzz\" : \"sleeping bored and tired\"\n}\n\nfrom nltk.tokenize import word_tokenize\ndef convert_abbrev_in_text(text):\n    tokens = word_tokenize(text)\n    tokens = [convert_abbrev(word) for word in tokens]\n    text = ' '.join(tokens)\n    return text\n\ndef convert_abbrev(word):\n    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:35.184289Z","iopub.execute_input":"2022-01-21T00:30:35.184836Z","iopub.status.idle":"2022-01-21T00:30:35.213604Z","shell.execute_reply.started":"2022-01-21T00:30:35.184795Z","shell.execute_reply":"2022-01-21T00:30:35.212682Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train[\"text\"] = train[\"text\"].apply(lambda x: convert_abbrev_in_text(x))\ntest[\"text\"] = test[\"text\"].apply(lambda x: convert_abbrev_in_text(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:40.288443Z","iopub.execute_input":"2022-01-21T00:30:40.288992Z","iopub.status.idle":"2022-01-21T00:30:42.363162Z","shell.execute_reply.started":"2022-01-21T00:30:40.288949Z","shell.execute_reply":"2022-01-21T00:30:42.362430Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:44.769636Z","iopub.execute_input":"2022-01-21T00:30:44.769914Z","iopub.status.idle":"2022-01-21T00:30:44.780838Z","shell.execute_reply.started":"2022-01-21T00:30:44.769873Z","shell.execute_reply":"2022-01-21T00:30:44.779991Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:49.868671Z","iopub.execute_input":"2022-01-21T00:30:49.868941Z","iopub.status.idle":"2022-01-21T00:30:49.878001Z","shell.execute_reply.started":"2022-01-21T00:30:49.868902Z","shell.execute_reply":"2022-01-21T00:30:49.877195Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from autogluon.text import TextPredictor \npredictor = TextPredictor(label='target', eval_metric='f1') ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T00:30:52.374559Z","iopub.execute_input":"2022-01-21T00:30:52.375211Z","iopub.status.idle":"2022-01-21T00:30:52.380666Z","shell.execute_reply.started":"2022-01-21T00:30:52.375172Z","shell.execute_reply":"2022-01-21T00:30:52.379778Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\npredictor.fit(train, time_limit=200)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T01:05:46.048414Z","iopub.execute_input":"2022-01-21T01:05:46.048725Z","iopub.status.idle":"2022-01-21T01:09:20.603798Z","shell.execute_reply.started":"2022-01-21T01:05:46.048689Z","shell.execute_reply":"2022-01-21T01:09:20.603053Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"y_pred = predictor.predict(test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-21T01:13:14.372573Z","iopub.execute_input":"2022-01-21T01:13:14.372879Z","iopub.status.idle":"2022-01-21T01:13:22.953250Z","shell.execute_reply.started":"2022-01-21T01:13:14.372848Z","shell.execute_reply":"2022-01-21T01:13:22.952427Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"submission['target'] = y_pred\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T01:13:48.003005Z","iopub.execute_input":"2022-01-21T01:13:48.003718Z","iopub.status.idle":"2022-01-21T01:13:48.016999Z","shell.execute_reply.started":"2022-01-21T01:13:48.003676Z","shell.execute_reply":"2022-01-21T01:13:48.016089Z"},"trusted":true},"execution_count":47,"outputs":[]}]}